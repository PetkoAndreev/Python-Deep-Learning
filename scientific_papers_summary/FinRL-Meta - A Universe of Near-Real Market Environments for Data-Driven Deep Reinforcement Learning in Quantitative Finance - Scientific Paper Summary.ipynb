{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "06522d0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d89fe5ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f417f5ec",
   "metadata": {},
   "source": [
    "<h1>FinRL-Meta: A Universe of Near-Real Market Environments for Data-Driven Deep Reinforcement Learning in Quantitative Finance<sup>1</sup></h1>\n",
    "<hr/>\n",
    "<h2>Authorts: Xiao-Yang Liu, ingyang Rui, Jiechao Gao, Liuqing Yang, Hongyang Yang, Zhaoran Wang, Christina Dan Wang, Jian Guo</h2>\n",
    "<h3>Scientific paper summary</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d576aa80",
   "metadata": {},
   "source": [
    "<h3>Abstract</h3>\n",
    "<h5>Problem Statement</h5>\n",
    "<p>Deep reinforcement learning (DRL)<sup>2</sup> has shown huge potentials in building financial market simulators recently. But the accuracy of DRL-based market simulators heavily relies on numerous and diverse DRL agents, which increases demand\n",
    "for a universe of market environments and imposes a challenge on simulation speed. </p>\n",
    "<h5>Problem Solution</h5>    \n",
    "<p>The paper introduce a FinRL-Meta<sup>3</sup> framework that builds a universe of market environments for data-driven financial reinforcement learning:\n",
    "    <ol>\n",
    "        <li>separates financial data processing from the design pipeline of DRL-based strategy and provides open-source data engineering tools for financial big data;</li>\n",
    "        <li>provides hundreds of market environments for various trading tasks;</li>\n",
    "        <li>enables multiprocessing simulation and training by exploiting thousands of GPU cores.</li>\n",
    "    </ol>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09167e91",
   "metadata": {},
   "source": [
    "<h3>Introduction</h3>\n",
    "<p>In quantitative finance<sup>4</sup>, market simulators play important roles in studying the complex market phenomena and investigating financial regulations. Compared to traditional simulation models, deep reinforcement learning (DRL) has shown huge potentials in building financial market simulators through multi-agent systems. However, due to the high complexity of real-world markets, raw historical financial data involve significant noise and may not reflect the future of markets. This issue usually degrades the fidelity of DRL-based simulation. The potentials of DRL-based market simulators are not fully explored yet. The already proposed FinRL Library contains a DRL framework, but it focuses on developing trading strategies instead of building market simulations.\n",
    "    \n",
    "Here the authors of this paper introduce a brand new FinRL-Meta framework that is a universe of near real-market environments\n",
    "for data-driven financial reinforcement learning:\n",
    "    <ol>\n",
    "        <li>DataOps paradigm is applied and unified and automated data processor for data accessing, data cleaning and feature engineering</li>\n",
    "        <li>Hundreds of near real-market DRL environments (connected to the data processor of FinRL-Meta framework) for various trading tasks (high-frequency trading, cryptocurrencies trading, stock portfolio allocation, etc.);</li> \n",
    "        <li>Utilization of thousands of GPU cores to perform multiprocessing training.</li>\n",
    "    \n",
    "<img src=\"https://raw.githubusercontent.com/AI4Finance-Foundation/FinRL-Meta/master/figs/neofinrl_overview.png\" alt = \"Overview of FinRL-Meta Architecture\" width=100%/>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6810f576",
   "metadata": {},
   "source": [
    "<h3>FinRL-Meta Framework Overview</h3>\n",
    "<ul>\n",
    "    <li><b>MDP (Markove Descision Process)<sup>5</sup> Model for Trading Tasks</b> - model a trading task as MDP\n",
    "$(S, A, P, r, \\gamma)$, where $S$ and $A$ denote the state space and action space, respectively, $P (s^\\prime|s, a)$\n",
    "denotes the transition probability, $r(s, a)$ is a reward function, and $\\gamma \\in (0, 1)$ is a discount factor.\n",
    "Specifically, the state denotes an observation that a DRL agent receives from a market environment; the action space consists of actions that an agent is allowed to take at a state; the reward function $r(s, a, s^\\prime)$ is the incentive for agents to learn a better policy. A trading agent aims to learn a policy $\\pi(s_t|a_t)$ that maximizes the expected return $R = \\sum^\\infty_{t=0} \\gamma^tr(s_t, a_t)$.</li>\n",
    "    <li><b>Overview of the framework</b> - FinRL-Meta consists of three layers: data layer, environment layer, and agent layer. Each layer executes its functions and is relatively independent.</li>\n",
    "    <li><b>DataOps for Data-Driven DRL in Finance</b> - FinRL-Meta follow the DataOps paradigm in the data layer.\n",
    "        <ol>\n",
    "            <li>establishment of a standard pipeline for financial data engineering, ensuring data of different\n",
    "                formats from different sources can be incorporated in a unified RL framework.</li>\n",
    "            <li>automation of the pipeline with a data processor, which can access and claen data, and extract features from various data sources with high quality and efficiency. Here are some of the data sources - Yahoo!Finance<sup>6</sup>, CCXT<sup>7</sup>, WRDS.TAQ<sup>8</sup>, Alpaca<sup>9</sup>, RiceQuant<sup>10</sup>, JoinQuant<sup>11</sup>, QuantConnect<sup>12</sup>\n",
    "        </ol>\n",
    "        <img src=\"https://raw.githubusercontent.com/AI4Finance-Foundation/FinRL-Meta/master/figs/finrl_meta_dataops.png\" alt=\"FinRL-Meta DataOps\" width=75%/>\n",
    "    </li>                    \n",
    "    <li><b>Multiprocessing Training</b> - utilization of thousands of GPU cores (CUDA cores) to perform multiprocessing training, which significantly accelerates the training process and improve the performance of DRL trading agents on large datasets.</li>\n",
    "    <li><b>Plug-and-Play</b> - separation of market environments from the data layer and the agent layer. Any DRL agent can be directly plugged into market environments, then trained and tested.</li>\n",
    "    <li><b>Training-Testing-Trading Pipeline</b> - the DRL agent first learns from the training environment and is then validated in the validation environment for further adjustment. Then the validated agent is tested on historical datasets. Finally, the tested agent will be deployed in paper trading or live trading markets.\n",
    "    <img src=\"https://raw.githubusercontent.com/AI4Finance-Foundation/FinRL-Meta/master/figs/timeline.png\" alt=\"Training-Testing-Trading Pipeline\" width=75%/></li>\n",
    "    <li><b>Supported Trading Tasks</b> - satisfactory trading performance for trading tasks such as stock trading, cryptocurrency trading, and portfolio allocation. Derivatives such as futures and forex are also supported.</li>\n",
    "        </ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9739f40c",
   "metadata": {},
   "source": [
    "<h3>Performance Evaluation</h3>\n",
    "<p>Here are some results of stock trading and cryptocurrency trading using FinRL-meta framework.</p>\n",
    "<h5>Experiment Settings</h5>\n",
    "\n",
    "<p><b><i>Stock trading task</i></b> - selection of the 30 constituent stocks in Dow Jones Industrial Average (DJIA). It's used the Proximal Policy Optimization (PPO) algorithm of ElegantRL, Stable-baselines3 and RLlib. Data used - from 06/01/2021 to 08/14/2021 for training and data from 08/15/2021 to 08/31/2021 for validation (backtesting). Data for retrain the agent - from 06/01/2021 to 08/31/2021 and trading from 09/03/2021 to 09/16/2021. Source - the Alpacaâ€™s database and paper trading APIs.</p>\n",
    "\n",
    "<p><b><i>Cryptocurrency trading task</i></b> selection of top 10 market cap cryptocurrencies. Again it's used PPO algorithm (of ElegantRL and the Bitcoin (BTC) price as the baseline). Data used - from 06/01/2021 to 08/14/2021 for training and from 08/15/2021 to 08/31/2021 for validation (backtesting). Data for retrain the agent - from 06/01/2021 to 08/31/2021 and trading from 09/01/2021 to 09/15/2021. Source - Binance.</p>\n",
    "\n",
    "<h5>Trading Performance</h5>\n",
    "\n",
    "<p><b><i>Stock trading</i></b> - in the backtesting stage, both ElegantRL and Stable-baselines3 agents\n",
    "outperform DJIA (baseline) in annual return and Sharpe ratio, as shown in Fig. 2 and Table 2. The ElegantRL\n",
    "agent achieves an annual return of 22.425% and a Sharpe ratio of 1.457. The Stable-baselines3 agent\n",
    "achieves an annual return of 32.106% and a Sharpe ratio of 1.621. In the paper trading stage, the\n",
    "results are consistent with the backtesting results.\n",
    "<img src=\"images/finrl_meta_stock_trading_graphics.png\" alt=\"stock trading graphics\" />\n",
    "<img src=\"images/finrl_meta_stock_trading_table.png\" alt=\"stock trading table\" /></p>\n",
    "\n",
    "<p><b><i>Cryptocurrency trading</i></b> - in the backtesting stage, the ElegantRL agent outperforms the benchmark\n",
    "(BTC price) in most performance metrics, as shown in Fig. 3 and Table 3. It achieves an annual return\n",
    "of 360.823% and a Sharpe ratio of 2.992. The ElegantRL agent also outperforms the benchmark\n",
    "(BTC price) in the paper trading stage, which is consistent with the backtesting results.\n",
    "<img src=\"images/finrl_meta_cryptocurrency_trading_graphics.png\" alt=\"stock trading graphics\" />\n",
    "<img src=\"images/finrl_meta_cryptocurrency_trading_table.png\" alt=\"stock trading table\" /></p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daf28e44",
   "metadata": {},
   "source": [
    "<h3>Code experiment<sup>13</sup></h3>\n",
    "<p>My code try (executred on Google Colab) were unsuccessful, because all the provided files from the authors ends with errors. Also there is no official guide how to test/implement the provided FinRL-Meta solution like for the other library of the same authors - FinRL (you can see more for it on my second scientific paper summary).</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1fb5ab6",
   "metadata": {},
   "source": [
    "<h3>Conclusions</h3>\n",
    "<p>In this paper, the authors followed the DataOps paradigm and developed a FinRL-Meta framework. FinRLMeta provides open-source data engineering tools and hundreds of market environments with multiprocessing simulation. For future work, authors will build a multi-agent based market simulator that will consists of over ten thousands of agents, namely, a FinRL-Metaverse. First, FinRL-Metaverse aims to build a universe of market environments. To improve the performance for large-scale markets, will be employed GPU-based massive parallel simulation as Isaac Gym. Moreover, it will be interesting to explore the evolutionary perspective to simulate the markets. The authors believe that FinRL-Metaverse will provide insights into complex market phenomena and offer guidance for financial regulations.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71dfced3",
   "metadata": {},
   "source": [
    "<h3>Resources</h3>\n",
    "<ol>\n",
    "    <li><a href=\"https://arxiv.org/pdf/2112.06753v1.pdf\">Arxiv Paper Source</a></li>\n",
    "    <li><a href=\"https://en.wikipedia.org/wiki/Deep_reinforcement_learning\">DRL Wikipedia</a></li>\n",
    "    <li><a href=\"https://github.com/AI4Finance-Foundation/FinRL-Meta\">FinRL-Meta Framework at GitHub</a></li>\n",
    "    <li><a href=\"https://corporatefinanceinstitute.com/resources/knowledge/finance/quantitative-finance/\">Quantitative Finance</a></li>\n",
    "    <li><a href=\"https://en.wikipedia.org/wiki/Markov_decision_process\">Markov Decision Process Wikipedia</a></li>\n",
    "    <li><a href=\"https://finance.yahoo.com/\">Yahoo!Finance</a></li>\n",
    "    <li><a href=\"https://github.com/ccxt/ccxt\">CCTX</a></li>\n",
    "    <li><a href=\"https://libguides.babson.edu/c.php?g=26412&p=161316\">WRDS.TAQ</a></li>\n",
    "    <li><a href=\"https://alpaca.markets/\">Alpaca</a></li>\n",
    "    <li><a href=\"https://rinkeby.etherscan.io/token/0x60bfa41fa438c96efb0df5904f6e23288cb86910\">RiceQuant</a></li>\n",
    "    <li><a href=\"https://github.com/JoinQuant\">JoinQuant</a></li>\n",
    "    <li><a href=\"https://www.quantconnect.com/\">QuantConnect</a></li>\n",
    "    <li><a href=\"./code_tests/\">Code Experiment</a></li>\n",
    "</ol>\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
